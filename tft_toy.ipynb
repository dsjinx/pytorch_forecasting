{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ede437d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /home/daokedao999/.local/share/jupyter/kernels/myenv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from tensorboard import program\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import EncoderNormalizer\n",
    "from pytorch_forecasting.metrics import QuantileLoss, SMAPE, MAPE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "print(\"Current Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d77e925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   time_idx      vals  group_ids\n",
      "0         0  0.000000         66\n",
      "1         1  0.020201         66\n",
      "2         2  0.040393         66\n",
      "3         3  0.060569         66\n",
      "4         4  0.080720         66\n",
      "5         5  0.100838         66\n",
      "6         6  0.120916         66\n",
      "7         7  0.140943         66\n",
      "8         8  0.160914         66\n",
      "9         9  0.180818         66\n",
      "(100, 3)\n",
      "time_idx       int64\n",
      "vals         float64\n",
      "group_ids      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create the 'time_idx' column with incremental values from 0 to 99\n",
    "time_idx = np.arange(100)\n",
    "#if there is a \"date\" column in the form of YYYY-MM-DD, the index can be created as follows:\n",
    "#data[\"time_idx\"] = (data[\"date\"] - data[\"date\"].min()).dt.days, \n",
    "#but the nonbusiness days are not considered in this case, so the resulting index will not be continuous\n",
    "\n",
    "# Create the 'values' column with values representing a sine wave\n",
    "time_points = np.linspace(0, 2, 100)\n",
    "values = np.sin(time_points)\n",
    "\n",
    "# Create the 'group_ids' column with a constant value of 66\n",
    "#group1 = np.full(50, 11)\n",
    "#group2 = np.full(30, 22)\n",
    "#group3 = np.full(20, 33)\n",
    "\n",
    "#group_ids = np.concatenate((group1, group2, group3), axis = 0)\n",
    "\n",
    "# Combine the columns into a dictionary\n",
    "data = {'time_idx': time_idx, 'vals': values, 'group_ids': 66}\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df.head(10))\n",
    "print(df.shape)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a4be66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_df shape: (50, 3)\n",
      "val_df shape: (30, 3)\n",
      "test_df shape: (20, 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#data slicing\n",
    "training_cutoff = 50\n",
    "train_df = df[lambda x: x.time_idx < training_cutoff]\n",
    "val_df = df[lambda x: (x.time_idx >= training_cutoff) & (x.time_idx < 80)]\n",
    "test_df = df[lambda x: x.time_idx >= 80]\n",
    "\n",
    "print(f\"\"\"\n",
    "train_df shape: {train_df.shape}\n",
    "val_df shape: {val_df.shape}\n",
    "test_df shape: {test_df.shape}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44fba0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check any NaN in the data:\n",
      "        train_df: False\n",
      "        val_df: False\n",
      "        test_df: False\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"check any NaN in the data:\n",
    "        train_df: {train_df.isna().any().any()}\n",
    "        val_df: {val_df.isna().any().any()}\n",
    "        test_df: {test_df.isna().any().any()}\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2300f2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "any inf in data:\n",
      "        train_df: False\n",
      "        val_df: False\n",
      "        test_df: False\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"any inf in data:\n",
    "        train_df: {train_df.isin([-np.inf, np.inf]).any().any()}\n",
    "        val_df: {val_df.isin([-np.inf, np.inf]).any().any()}\n",
    "        test_df: {test_df.isin([-np.inf, np.inf]).any().any()}\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02076803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the TimeSeriesDataSet\n",
    "train_dataset = TimeSeriesDataSet(\n",
    "    train_df,\n",
    "    group_ids=[\"group_ids\"],\n",
    "    target=\"vals\",\n",
    "    time_idx=\"time_idx\",\n",
    "    max_encoder_length = 5,\n",
    "    max_prediction_length = 2,\n",
    "    time_varying_unknown_reals=[\"vals\"],\n",
    "    target_normalizer=EncoderNormalizer(transformation=\"softplus\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a72b7a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = TimeSeriesDataSet.from_dataset(\n",
    "    train_dataset,\n",
    "    val_df #keep the predict=False as default is to create a sliding window set over all the data\n",
    ")\n",
    "test_dataset = TimeSeriesDataSet.from_dataset(\n",
    "    train_dataset,\n",
    "    test_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efc83835",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = train_dataset.to_dataloader(\n",
    "    train=False, #keep the \"train=False\" is to sliding through the whole dataset\n",
    "    batch_size=100 #make the \"batch size\" >> than the dataset size is to align with the sliding window effect\n",
    ")\n",
    "val_dataloader = val_dataset.to_dataloader(\n",
    "    train=False,\n",
    "    batch_size=100\n",
    ")\n",
    "test_dataloader = test_dataset.to_dataloader(\n",
    "    train=False,\n",
    "    batch_size=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "678b8f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 666\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 5.267k\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(666)\n",
    "\n",
    "lr_tune_logger = TensorBoardLogger(save_dir = \"\", version = \"lr\")  # logging results to the current pwd\n",
    "lr_early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\", min_delta=1e-4, patience=10, mode=\"min\"\n",
    ")\n",
    "\n",
    "#set up trainer for tunning\n",
    "lr_trainer = pl.Trainer(\n",
    "    accelerator = \"gpu\",\n",
    "    devices = \"auto\",\n",
    "    gradient_clip_val = 0.1,\n",
    "    #fast_dev_run=True,  # comment in for debugging, only 1 training and 1 validation batch to run\n",
    "    callbacks=[lr_early_stop_callback],\n",
    "    logger = lr_tune_logger #if the logger is not set, the default loger will be saved under default name = version_0\n",
    ")\n",
    "\n",
    "#set up tft for tunning \n",
    "tft_tuner = TemporalFusionTransformer.from_dataset(\n",
    "    train_dataset,\n",
    "    # dummy lr required for the following lr_finder initiation\n",
    "    learning_rate = 0.06,\n",
    "    hidden_size = 8,  # most important hyperparameter apart from learning rate\n",
    "    lstm_layers = 2,  # set to 2 or 3 for large datasets\n",
    "    # number of attention heads. Set to up to 4 for large datasets\n",
    "    attention_head_size = 2,\n",
    "    dropout = 0.1,  # between 0.1 and 0.3 are good values\n",
    "    loss = QuantileLoss(), \n",
    "    #quantiles = [0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98] as defined in `pytorch_forecasting.metrics.quantile.QuantileLoss` source code\n",
    "    reduce_on_plateau_patience = 100\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft_tuner.size() / 1e3:.3f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7793359e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Finding best initial lr: 100%|██████████| 100/100 [01:22<00:00,  1.20it/s]`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Finding best initial lr: 100%|██████████| 100/100 [01:22<00:00,  1.21it/s]\n",
      "Learning rate set to 0.012589254117941664\n",
      "Restoring states from the checkpoint path at /home/daokedao999/.local/share/jupyter/kernels/myenv/.lr_find_08f978b7-1524-48a8-8f10-d9b8884d0e93.ckpt\n",
      "Restored all states from the checkpoint at /home/daokedao999/.local/share/jupyter/kernels/myenv/.lr_find_08f978b7-1524-48a8-8f10-d9b8884d0e93.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suggested learning rate: 0.012589254117941664\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAG1CAYAAAAC+gv1AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAVLBJREFUeJzt3Xl8VNXdx/HPTPY9JIEsEAjIvoU9QqtoTQlKVdTKUirIw4NLFZcorajFrYpWsajQUlwqWhBEK/pQisUIghBZwq6syhIgKyH7PjPPHyGjCQECZObOJN/36zUvzZ1z7/zuJTJfzzn3XJPNZrMhIiIiInZmowsQERERcTUKSCIiIiL1KCCJiIiI1KOAJCIiIlKPApKIiIhIPQpIIiIiIvUoIImIiIjUo4AkIiIiUo+n0QW4K6vVysmTJwkKCsJkMhldjoiIiDSCzWajqKiImJgYzOZz9xMpIF2ikydPEhsba3QZIiIicgnS09Np167dOd9XQLpEQUFBQM0FDg4ONrgaERERaYzCwkJiY2Pt3+PnooB0iWqH1YKDgxWQRERE3MyFpsdokraIiIhIPQpIIiIiIvUoIImIiIjUo4AkIiIiUo8CkoiIiEg9CkgiIiIi9SggiYiIiNSjgCQiIiJSjwKSiIiISD0KSCIiIiL1KCCJiIiI1KOAJCIiIlKPHlYr0gwVlFZxILuIg1nFHMwuorTCQqCvJwE+ngT5eBLo60lksA/RIX5Eh/gS4ud1zgc32mw2TpVUciyvlJP5ZWQXVpBdVEFOUQX5pZW0DvIhNsyfdq38aB/mT9tWfkQE+GA2n/9BkCIirkwBScRgpZXVHMgq5uipEqosNqxWG1abDYvNhreHmSBfL4J9PQny9cLfx4OKKitlVRbKKi2UVlaTW1zJ8dOlnMgv4/jpMo7llZJTVHFRNfh5eRAe6E2gjyf+3h4E+Hji5WHmZH4Z6XmllFRaLup4nmYTbYJ8iAzxJTrEl44RAVzROpDObQLp1DqQQB9Pqi1WSiosFFdWU1ZZTZXFhsVqw2YDi81GsK8nceEBCloiYggFJBEHOJlfRtrR06QdPc22Y6c5lF1MiJ8XEYE+RAR6ExHoQ35ZFfszi0g/XYrN1vQ1xIT40iUyiC5tAgn196K4wkJJRTXFFdUUllWRWVhORkE5eSWVlFVZOH667JzHMpkgOtiXmFA/IoN9aR3kQ+sgH1r5e5NdVM6xvFKO59WEs6yicqqtNk4WlHOyoJztDRzP29NMZbX1gucQ7OtJfGwo/WND6dMuFICCsioKy6ooKKui2mrFz8sDXy8P/Lw98Pf2oF0rfzpFBBAW4H3OXjERkQtRQBJpAkXlVWz8/hRfHcjhq/05nMg/O2yUVlrIKChvcP+IQB+uaB2An7cHZpPpzAsqLVYKy6ooKq+mqLyaksrqmjDgVRMGfL08CAvwpl0rP9q18qNtaM1QV6fWAQT5ejWq9vKqmrpOl1ZSWmGhpLKakopqKqqtRAX70j7cn7ahfvh6eTTqeFUWKzlFFWQWlpNVUM6J/DIO55bwfU4xh7JLyC2uqBOOvD3M+Pt44Gk242EGD5MJs9lEbnEFheXVrD+Yy/qDuY367J8K8fOiU+sAukcF87PO4Qy7IoKwAO+LPo6ItEwmm80R/+/a/BUWFhISEkJBQQHBwcFGlyNOUGWxsvXIaY7llZBXUkV+aSV5JZUczStl29HTVFt//E/Jw2yiZ3QwAzu0YkCHVvSMDqKkwkJuccWZVyV+Xh50jwqiW1QQ4YE+Bp6ZcxWUVlFUUXVmOM8Tb8+G7xWpsljZn1nE9vR8dhzLZ29GIV6eZoJ9PQnx8yLYzwtvDzPlVRb7kGNxRTVHT5U2GFBNJugVE8zPOkcwJC6M/u1bKTCJtECN/f5WQLpECkgtQ0FZFV8dyOGL77JYsz+bovLqc7btGBHA8K6tGd61NUM6hhHgow5ao5RVWjicW8IPucVsP5bP1wdz2Z9VdFa7jhEB9G8fSv/2regZHUz3qCD9uYk0cwpIDqaA5N7ySys5mF1McUW1fViprNJCTlEFJ/PLOJFfRsaZ4SHLT3qGwgO86dMuhLAAb8IDvGkVUDOfKKFjGB3CAww8I7mQ7MJyNnyfy4ZDp9h29DQ/5Jac1cZkgrjwAHpEB9EtMpiukYF0iQwiLtwfTw+tiiLSHCggOZgCkns5eqqk5ovxWM2k6R9yzv5yPJcubQJJ7BlJYo9I+sWG4qG7qpqF0yWV7EjPZ9ux0+w6XsDejEKyz3H3n7eHmZhQX/y8PfHzMuPn7YGflyc9ooMYekU4A9q3avQcLRExlgKSgykguQer1cb8dd8z+78H6vQEAbQN9aNVgBf+Xp74+9RMeg4P8CEm1I+Y0Jo7tmJb+RMV4mtQ9eJsucUV7M0oZG9GIQeyijmQVbOWVFnV+Zc58PE0MyiuFUPiwukRHUSP6GDahvppiQIRF6SA5GAKSK7vVHEFyR/u5KsDOQAM6tCKKzuFM6BDKP1jW9FKE3SlEaxWm33ItXZCeHmVhcKyKrYePc3G7081uO5UgLcH3aKC+FnnCK7vHU2P6CAtOyDiAhSQHEwBybVt+uEUDyzZTlZhBb5eZp69qTe3D2qnLyhpcjabje9zitlw6BQ70/PZm1nE99nFVFrqrvMUF+7P9X2iub53FL1jQtS7JGIQBSQHU0ByPTabjbSjp1m6JZ2Ptx3HaoPObQKZ95sBdIsKMro8aUGqLFYO55aw+3gB//0uk7X7c6j4ydpPkcE+/KJ7JIk92vCzzhGavyTiRApIDqaA5DqyC8v5aNtxPtp6vM6dSbcNaMdzo3vh763btsVYJRXVrNmfzcrdGazdn0PpTx7d4utlZmincK7q0pqru0ZwRetA9XSKOJACkoMpILmG/9t5kukf7aS8qub/zv29PRjVJ5oxg2MZHBdmcHUiZ6uotvDND3mk7M0iZW/2WYtaxoT4MvSKCHq3Da5Zmyk6mBC/xq2KLiIXpoDkYApIxrJabbyWcpDXUg4CEN8uhAkJHbihbzSBWuhP3ITNZmN/VhHrDuSw/mAumw7nNfiMunat/EjoGM4ve0ZyVZcILWYpchkUkBxMAck4ZZUWHl22k3/vzgBg6lUdeez6HlqfSNxeeZWFTYfzSDt6mu9O1iw3UL+HydvTzM+uCCexZyQjekbROqjlPKZGpCkoIDmYApIxsgrL+d+FW9l9ogAvDxPPj+7DmMGxRpcl4jAFpVXsPlHAmv3ZrP4ui2N5pfb3zCYYHBfGDX2iGdk7ishgrdklciEKSA6mgOR8xRXV3PrXDRzIKqaVvxfzfzuQhE7hRpcl4jQ2m41D2cX897ss/vtdFjvT8+3vmUww7IpwJiR04Jc9I/HSo1FEGqSA5GAKSM5ltdq4+59prP4uizZBPnx0zzDah/sbXZaIoY6fLmXVnkz+syeTtKOn7dtbB/kwZlA7xg1uT2yY/jsR+SkFJAdTQHKuV/+7n9e/PIS3p5mld11J//atjC5JxKUcP13K0i3pLNmSbl/Z22SCKzuGc+uAtlzfRzcwiIACksMpIDnPyt0Z/G7RNgBm3x7PbQPbGVyRiOuqslj54rssFm06xteHcu3bfb3MjOwVxfgh7RnSMUxrLUmLpYDkYApIzvHdyUJu+9tGyqosTPl5R/74q55GlyTiNo6fLuXTHSf5OK3uIqrx7UKYenUnRvaKwlNzlaSFUUByMAUkxyquqOazHSd548uDZBSUc1WXCP5x52D9ZS5yCWw2GzuPF7B0Szr/2nbc/tiT2DA/pvysI+OGtNfjTqTFUEByMAUkx9hzooDFm4/x6fYTlJx5HEPHiACW/+5nhPhrNWGRy5VbXMH7qUd5L/UIp0urAIgI9OGe4Z2YkNABP28FJWneFJAcTAGpaZVVWvj9x7v4v50n7ds6RQTwm4T23D4oVo9aEGliZZUWPkpLZ/5XP9gXo4wI9Oauqzvx2ys76BmG0mwpIDmYAlLTySwoZ+p7NYs/eppNjOwdxYSEDlzZSRNJRRytstrKJ9uPM3fNIdLzaoOSDw9c15lxg9vj7alhbWleFJAcTAGpaew6ns//LtxKdlGFFn8UMVCVxcon208w98tD9tW6Y8P8eOSX3bgpPgazHuUjzYQCkoMpIF2+lbszSP5wB+VVVrq0CeTtSYO1+KOIwSqrrSzdms7rKQft6yl1jwriocSuJPWKVK+uuD0FJAdTQLo8P13b6JpurXljfH+CfDXPSMRVlFZW848NR5j/1fcUlVcD0DM6mIcSu/DLngpK4r4UkBxMAenS7Tqez5i/p1JeZWX8kFj+NLoPHuq+F3FJ+aWVvLX+MP/YcNh+Z2mvmGAeTuzKdT3aKCiJ21FAcjAFpEuTUVDGzXM3kF1UwTXdWvP2pMEKRyJu4HRJJW99/QPvbjhiD0rxsaE88suuXNUlQkFJ3IYCkoMpIF280spqbp+fyrcnC+kaGcjH9w7TsJqIm8krqWTBuh9YuPEIZVU1QWlIXBiPjOiqGyzELSggOZgC0sWxWm3cuyiNz7/NIizAm0/v+5meMi7ixnKKKvjb2u/556ajVJ5ZmXtUn2j++KueRIX4GlydyLkpIDmYAlLjpeeV8uKqffx7VwbeHmYWT01gUFyY0WWJSBPILCjnjS8PsmRLOharjQBvDx7+ZVcmDYvDS48GEhekgORgCkgXll1Yztw1h/hg8zGqLDZMJph9ezy3DmhndGki0sS+O1nIk8t3s+1YPgDdIoN4/pbe+p8hcTkKSA6mgHRuVquNOV8cYMH6Hyivqul6v6pLBI+O6EZ8bKixxYmIw1itNj5KO86s/+zldGkVJhPcOSyO6Und9OgScRkKSA6mgHRuizYd5YlP9gDQv30o05O6MeyKCIOrEhFnOV1SyQsr97Is7TgAHcL9eem2vlypSdziAhSQHEwBqWFF5VVc+8pacosreXREV+67trNu/xVpodbuz2bGv3aTUVAOwMShHXjs+u7qTRJDNfb7WzPopEnN/+p7cosr6RgRwF1XX6FwJNKCXdOtDZ8/fDXjh8QC8F7qUa5/bT1bjuQZXJnIhRkekObNm0dcXBy+vr4kJCSwefPm87ZftmwZ3bt3x9fXlz59+rBy5co67995552YTKY6r5EjR9ZpExcXd1abF198scnPraU5mV/GW+sPA/DY9d31FHARIdjXi1m39uX9KUOICfHl6KlSxvw9lRdW7qX8zDpKIq7I0G+wpUuXkpyczFNPPcW2bduIj48nKSmJ7OzsBttv3LiR8ePHM2XKFLZv387o0aMZPXo0e/bsqdNu5MiRZGRk2F8ffPDBWcd69tln67SZNm2aQ86xJXnl8/1UVFsZ0jGMET0jjS5HRFzIVV1as+rhq7l9YDtsNliw7gd+9cbX7D5eYHRpIg0yNCC9+uqrTJ06lcmTJ9OzZ0/mz5+Pv78/77zzToPtX3vtNUaOHMn06dPp0aMHzz33HAMGDGDu3Ll12vn4+BAVFWV/tWrV6qxjBQUF1WkTEBDgkHNsKXYfL+Bf208A8OSoHhpaE5GzBPt68fLt8bw1cRARgT4cyi7m1r9t4O2vD6PpsOJqDAtIlZWVpKWlkZiY+GMxZjOJiYmkpqY2uE9qamqd9gBJSUlntV+7di1t2rShW7du3HvvvZw6deqsY7344ouEh4fTv39/Xn75Zaqrq89bb0VFBYWFhXVeUsNms/Gnf38HwC3929K3XaixBYmIS0vsGcnqh69mZK8oqiw2nlvxHXe9n0Z+aaXRpYnYGRaQcnNzsVgsREbWHYqJjIwkMzOzwX0yMzMv2H7kyJG89957pKSk8NJLL/HVV19x/fXXY7H8ONb9wAMPsGTJEtasWcPdd9/NCy+8wO9///vz1jtr1ixCQkLsr9jY2Is95WZr9XdZbDqch4+nmUeTuhldjoi4gVYB3vzttwN49uZeeHuYWf1dFqNe/5ptx04bXZoIAM3uXstx48bZ/71Pnz707duXK664grVr13LdddcBkJycbG/Tt29fvL29ufvuu5k1axY+Pj4NHnfGjBl19issLFRIAkoqqnnuTO/RlJ93pG2on8EViYi7MJlMTBwax4D2rbhv8baaCdzzU5l5Y0/uuLKDhurFUIb1IEVERODh4UFWVlad7VlZWURFRTW4T1RU1EW1B+jUqRMREREcOnTonG0SEhKorq7myJEj52zj4+NDcHBwnZfAy5/vJz2vjLahfvzu2s5GlyMibqh32xBWTPs5v+obTbXVxsxPv+XxT3bbH4IrYgTDApK3tzcDBw4kJSXFvs1qtZKSksLQoUMb3Gfo0KF12gOsXr36nO0Bjh8/zqlTp4iOjj5nmx07dmA2m2nTps1FnkXLtvVIHgtTjwAw69Y+BPo0uw5JEXGSIF8v3hjfnxnXd8dkgg82p/ObN78hp6jC6NKkhTL0Lrbk5GTefPNNFi5cyN69e7n33nspKSlh8uTJAEycOJEZM2bY2z/44IOsWrWK2bNns2/fPp5++mm2bt3K/fffD0BxcTHTp0/nm2++4ciRI6SkpHDzzTfTuXNnkpKSgJqJ3nPmzGHnzp388MMPLFq0iIcffpjf/va3Dd7tJg0rr7Lw+493YbPB7QPbcXXX1kaXJCJuzmQycffwK3jnzsEE+Xqy9ehpbp77NXtOaCkAcT5DA9LYsWN55ZVXmDlzJv369WPHjh2sWrXKPhH72LFjZGRk2NsPGzaMxYsXs2DBAuLj4/noo49Yvnw5vXv3BsDDw4Ndu3Zx00030bVrV6ZMmcLAgQNZv369fW6Rj48PS5YsYfjw4fTq1Yvnn3+ehx9+mAULFjj/Arix11IO8kNOCa2DfHhyVE+jyxGRZuTabm1Yft/P6BQRwMmCcm6fn8qqPQ3fvCPiKHoW2yVqyc9i2328gNF/3YDFauPvdwwkqde554CJiFyqgrIqpn2wnXUHcjCZ4A8ju3P31Z00eVsui57FJg5RZbEy/aOdWKw2ftU3WuFIRBwmxM+LdyYNYuLQDths8OJ/9vH7j3Zp8rY4hQKSXJR3vj7MvswiWvl78cxNvYwuR0SaOU8PM8/e3Junb+yJ2QTL0o5zx9ubKCitMro0aeYUkKTRMgrKeC3lIAAzbuhBeGDDa0aJiDS1O3/WkbfvHEygjyebDucx7s1vyC3WHW7iOApI0mh/+vdeSistDOzQil8PaGd0OSLSwlzbrQ3L7hlKRKAPezMKGfv3VDILyo0uS5opBSRplK8P5vLvXRmYTfDszb0wmzVJUkScr0d0MB/efSUxIb58n1PC7X/fSHpeqdFlSTOkgCQXVFltZeZnewCYODSOXjEhBlckIi1Zp9aBfHjPUDqE+5OeV8bt81M5lF1sdFnSzCggyQW9/fVhfsgpISLQm4d/2dXockREaNfKn2V3D6VrZCCZheWMW6CQJE1LAUnO62R+Ga/XTsy+vgchfl4GVyQiUqNNsC9L7hpKz+hgcosr+c2b33A4t8TosqSZUECSc7LZah4aWVZlYXBcK24d0NbokkRE6ggL8Oaf/5tA96ggsosq+M2b33DslOYkyeVTQJJz+uemY3yxNwsvDxPP3txbq9eKiEuqDUmd2wSSUVDO+De/4fhphSS5PApI0qB9mYU8t+I7oGZ5/x7RLetxKiLiXiICfVj8vwl0igjgRH4Zv3lzk5YAkMuigCRnKau0MG3xdiqrrVzbrTVTft7R6JJERC6oTbAvi6deSYdwf47llTLpnc0UlGnFbbk0CkhylmdXfMfB7GJaB/nw8u3xGloTEbcRFeLLP6ck0CbIh/1ZRdz13lbKqyxGlyVuSAFJ6li5O4MPNh/DZII5Y/sRoceJiIibiQ3z5x+Tf3wsSfKHO7BYbUaXJW5GAUnssovKeezjXQDcM/wKftY5wuCKREQuTa+YEBbcMRAvDxMrd2fy3IrvsNkUkqTxFJDEbsXODArLq+kRHUyyFoQUETc3rHMEs8f0A+DdjUeY/9UPxhYkbkUBSey+3JcNwG0D2uLloV8NEXF/N8XH8OSoHgC8tGofn+08aXBF4i70LSgAFJVXsenwKQCu6xFpcDUiIk3nf6/qxP/8rOZu3EeX7WTLkTyDKxJ3oIAkAKw7kEuVxUan1gF0jAgwuhwRkSb1xKgejOgZSWW1lanvbdUjSeSCFJAEgJS9WQAkqvdIRJohD7OJ18b1J75dCPmlVUz+x2bySiqNLktcmAKSYLHaWLO/Zv7Rdd3bGFyNiIhj+Hl78NakwbRr5ceRU6VaI0nOSwFJ2HbsNKdLqwjx82Jgh1ZGlyMi4jCtg3z4x52DCfL1ZOvR0zz92bdGlyQuSgFJ+OLM8Nq13VrjqbvXRKSZ6xIZxF8nDMBkgiVb0vk47bjRJYkL0rehkLK3ZnjtF5p/JCItxFVdWvPQdTXrvT25fA8HsooMrkhcjQJSC3f0VAmHsovxNJsY3rW10eWIiDjN/b/ozFVdIiirsnDvP9Moqag2uiRxIQpILdwXZ3qPBseFEeLnZXA1IiLO42E28Zex/YgM9uH7nBIe/2S3HkcidgpILdyX+2rmH13XQ3eviUjLExHow9zfDMDDbOLTHSdZtOmY0SWJi1BAasEKy6vY9EPNirJa/0hEWqrBcWH8PqkbAM+u+I6Dmo8kKCC1aOsO5FBttXFF6wDitHq2iLRgd13dieFdW1NZbeXhD3dQWW01uiQxmAJSC1Z795p6j0SkpTOZTPz5130J9fdiz4lCXk85aHRJYjAFpBaqotpiX/8osacCkohIZLAvL9zSB4C/rj1E2lE91LYlU0Bqob4+mEtReTVtgnwY2F6rZ4uIANzQJ5pb+rfFaoPkD3fq1v8WTAGphfr3rgyg5i8Ds9lkcDUiIq7j6Zt6ERPiy9FTpfzp33uNLkcMooDUApVXWVj9Xc3w2o3x0QZXIyLiWkL8vHhlTDwAH2w+xpp92QZXJEZQQGqB1h/MpaiimugQX/rHanhNRKS+YVdE8D8/6wjUPIpEQ20tjwJSC7Ri10lAw2siIufzaFJX2rXy40R+Ga+uPmB0OeJkCkgtTHmVhS/ODK+N6qvhNRGRc/H39uRPo3sD8I8Nh9l1PN/YgsSpFJBamLX7cyiptNA21I/+saFGlyMi4tKu6daGm/vFYLXBYx/vptqiBSRbCgWkFubfu2vuXhvVNxqTScNrIiIX8sdf9STEz4vvMgp5Z8Nho8sRJ1FAakHKKi2knFkcclQfDa+JiDRGRKAPT4zqAcBfVh8kPa/U4IrEGRSQWpC1+7MprbTQrpUffduFGF2OiIjbuH1gO67sFEZZlYUnl+/BZrMZXZI4mAJSC7JCw2siIpfEZDLxwi198PY089WBHFbuzjS6JHEwBaQWorSymi/PPJz2V31iDK5GRMT9dGodyO+uuQKAZ/7vW4rKqwyuSBxJAamF+OaHU5RVWYgN86N322CjyxERcUv3DL+CuHB/sosqtDZSM6eA1ELszywGoH9sKw2viYhcIl8vD547szbSwo1H2HOiwOCKxFEUkFqI73NqAlLnNoEGVyIi4t6u6tKaG+Nr1kZ6YvkeLFZN2G6OFJBaiEPZCkgiIk3lj6N6EOTjyc70fD7YfMzocsQBFJBaAJvNxvdnAtIVrRWQREQuV5tgXx4Z0RWAl1btI6eowuCKpKkZHpDmzZtHXFwcvr6+JCQksHnz5vO2X7ZsGd27d8fX15c+ffqwcuXKOu/feeedmEymOq+RI0fWaZOXl8eECRMIDg4mNDSUKVOmUFxc3OTn5iqyiyooqqjGbIK4CH+jyxERaRbuGBpHn7YhFJVX86d/f1ez0WaD3Fw4cqTmn1ovyW0ZGpCWLl1KcnIyTz31FNu2bSM+Pp6kpCSys7MbbL9x40bGjx/PlClT2L59O6NHj2b06NHs2bOnTruRI0eSkZFhf33wwQd13p8wYQLffvstq1evZsWKFaxbt4677rrLYedptNreow7hAfh4ehhcjYhI8+BhNvH8Lb0xm2DNNwc49MTz0KULtG4NHTvW/LNLF3jtNcjPN7pcuUgmm4HLgSYkJDB48GDmzp0LgNVqJTY2lmnTpvHYY4+d1X7s2LGUlJSwYsUK+7Yrr7ySfv36MX/+fKCmByk/P5/ly5c3+Jl79+6lZ8+ebNmyhUGDBgGwatUqbrjhBo4fP05MTOPWCCosLCQkJISCggKCg137tvn3Uo8w89NvSezRhrcmDTa6HBGRZuWfzyzglucfxK+qApMJTD/9Wq29a9jfHz7+GJKSjClS7Br7/W1YD1JlZSVpaWkkJib+WIzZTGJiIqmpqQ3uk5qaWqc9QFJS0lnt165dS5s2bejWrRv33nsvp06dqnOM0NBQezgCSExMxGw2s2nTpnPWW1FRQWFhYZ2Xu6idoH2FJmiLiDStzz9nwnO/w7e6AjO2uuEIaobYbDYoK4NRo+Dzz42pUy6aYQEpNzcXi8VCZGRkne2RkZFkZja8hHtmZuYF248cOZL33nuPlJQUXnrpJb766iuuv/56LBaL/Rht2rSpcwxPT0/CwsLO+bkAs2bNIiQkxP6KjY29qPM1kv0ONk3QFhFpOvn5cNttmGw2PC40GGO11gSl227TcJubMHySdlMbN24cN910E3369GH06NGsWLGCLVu2sHbt2ss67owZMygoKLC/0tPTm6ZgJ9AaSCIiDrBwIZSW1oSfxrBaa9q/955j65ImYVhAioiIwMPDg6ysrDrbs7KyiIqKanCfqKioi2oP0KlTJyIiIjh06JD9GPUngVdXV5OXl3fe4/j4+BAcHFzn5Q4Ky6vIKqy5/VRDbCIiTcRmgzfeuLR9X39dd7e5AcMCkre3NwMHDiQlJcW+zWq1kpKSwtChQxvcZ+jQoXXaA6xevfqc7QGOHz/OqVOniI6Oth8jPz+ftLQ0e5svv/wSq9VKQkLC5ZySS6q9g61NkA/Bvl4GVyMi0kycOgXff3/xQcdmq9kvL88xdUmTMXSILTk5mTfffJOFCxeyd+9e7r33XkpKSpg8eTIAEydOZMaMGfb2Dz74IKtWrWL27Nns27ePp59+mq1bt3L//fcDUFxczPTp0/nmm284cuQIKSkp3HzzzXTu3JmkM3cO9OjRg5EjRzJ16lQ2b97Mhg0buP/++xk3blyj72BzJ9/nlAAaXhMRaVKXu3ZeUVHT1CEO42nkh48dO5acnBxmzpxJZmYm/fr1Y9WqVfaJ2MeOHcNs/jHDDRs2jMWLF/Pkk0/y+OOP06VLF5YvX07v3jUPDvTw8GDXrl0sXLiQ/Px8YmJiGDFiBM899xw+Pj724yxatIj777+f6667DrPZzG233cbrr7/u3JN3Ej1iRETEAQIv8+/UoKCmqUMcxtB1kNyZu6yD9L8Lt/LF3iyeuakXk4bFGV2OiEjzYLPVLAL5ww8XN8xmMkGnTnDw4I9rJIlTufw6SOIcuoNNRMQBTCaYNu3S9n3gAYUjN6CA1IxVVFs4llcKKCCJiDS5SZNqVsg2N/Kr1GyuaT9xomPrkiahgNSMHT1VisVqI9DHkzZBPhfeQUREGi80tObxISbTBUOS1WSqafevf9XsJy5PAakZ++kjRkzqzhURaXpJSfDvf4OfX00Aqvd3rc1kwoqJMk8fdv59MYwYYVChcrEUkJoxPWJERMQJkpLg+HGYM6dmAvZPmDp14r9TH+PK+xbyu5wISiqqjalRLpoCUjOmCdoiIk4SGloz+frgQcjNhcOHa/558CBXvfEsIVERnMgv48+r9hldqTSSAlIzZh9iax1gcCUiIi2EyQTh4RAXV/NPk4kAH09evLUvAAtTj7L5sFbRdgcKSM2U1WpTD5KIiIv4eZcIxg6KBeAPH++ivMpicEVyIQpIzdTJgjLKq6x4e5hpH+ZvdDkiIi3e46N6EBnsw+HcEv7yxQGjy5ELUEBqpmqH1+Ii/PH00B+ziIjRQvy8+NPoPgC8ue4HdqbnG1uQnJe+OZupH+cfaXhNRMRV/LJnJDfFx2C1we8/0lCbK1NAaqY0/0hExDU9fVMvIgK92Z9VxMuf7ze6HDkHBaRm6vvsEkABSUTE1YQFePPnX9fc1fb214dZdyDH4IqkIQpIzdTRvJqAFBeuW/xFRFzNL7pHMnFoBwAeWbaTvJJKgyuS+hSQmqHyKgtZhRUAxOoONhERl/T4DT3o3CaQnKIK/vDxLmw2m9ElyU8oIDVDJ/LLAPD39qCVv5fB1YiISEN8vTx4bVw/vD3MrP4uiw82pxtdkvyEAlIzlJ5XCkBsK389pFZExIX1ignh9yO7AfDsim/tdyCL8RSQmqHjp2t6kGLD/AyuRERELuR/ftaRn3eOoLzKyl3vbaWgrMrokgQFpGYp/XRND1K7Vpp/JCLi6sxmE38Z24+YEF9+yC1h2gfbqbZYjS6rxVNAaoaO59X2ICkgiYi4g9ZBPiyYOAg/Lw/WHcjhhZX7jC6pxVNAaoZ+7EHSEJuIiLvo3TaE2WPiAXhnw2E+3KJJ20ZSQGqG7HOQNMQmIuJWbugTzUOJXQB4YvluthzJM7iilksBqZkpqai2LzimSdoiIu7ngV904YY+UVRZbNz9fho/5OjONiMoIDUztcNrof5eBPlqDSQREXdjNpt45fZ4+rQNIa+kkonvbCa7sNzoslocBaRmJv3MBG3NPxIRcV/+3p68c+dgOoT7c/x0GZP+sYXCct3+70wKSM3M8dM/LhIpIiLuq3WQD+/9zxAiAn3Ym1HIXe9tpbzKYnRZLYYCUjOTrlv8RUSajQ7hAbw7eTCBPp5880MeDy/dgcWqZ7Y5gwJSM5Nu70HSEJuISHPQu20IC+4YiLeHmf/syWTGv3ZhVUhyOAWkZqb2OWzt1IMkItJsDOscwZxx/TCb4MOtx3n8k90KSQ6mgNSM2Gy2n6yBpB4kEZHm5IY+0fxlbE1IWrIlnSeWKyQ5kgJSM1JQVkVxRTWg57CJiDRHN/draw9JH2xO58lP9ygkOYgCUjNSO0G7dZAPvl4eBlcjIiKOcHO/tsweE4/JBIs3HWPmZ3uw2RSSmpoCUjOiCdoiIi3DLf3bMfv2mpD0z2+O8efP9xtdUrOjgNSM2Cdoa3hNRKTZu3VAO2bd0geAv639nvlffW9wRc2LAlIzYp+grWewiYi0COOGtGfG9d0BePE/+/hg8zGDK2o+FJCakXStoi0i0uLcPfwK7r3mCgAe/2Q3/96VYXBFzYMCUjNSO8SmVbRFRFqW3yd1Y/yQ9ths8NDS7Xx9MNfoktyeAlIzUXcNJAUkEZGWxGQy8afRvRnVN5oqi417F6VxKLvY6LLcmgJSM5FTVEFFtRWzCaJDfY0uR0REnMzDbOLVMfEM6tCKovJqpizcQl5JpdFluS0FpGYi/UzvUXSIH14e+mMVEWmJfDw9+PsdA4kN8+PoqVLu+WcaldVWo8tyS/ombSaOn669xV93sImItGThgT68PWkwQT6ebD6cxxOf7NZCkpdAAamZ0ARtERGp1TUyiDd+0x+zCZalHWfBuh+MLsntKCA1E7WPGdEEbRERAbimWxv++KueALy4ah8bv9edbRdDAamZOJ6vITYREanrzmFx3D6wXc3t/0t2kFtcYXRJbkMBqZmw9yBpiE1ERM4wmUw8c3MvOrcJJLuogkc+3InVqvlIjaGA1AxYrDZO5usxIyIicjZ/b0/m/WYAPp5mvjqQw5vrNR+pMRSQmoGMgjKqrTa8PExEBmkNJBERqatbVBBP3dgLgJc/38+2Y6cNrsj1KSA1A7UraLcN9cNsNhlcjYiIuKLxQ2IZ1TeaaquNBz7YTkFZldEluTTDA9K8efOIi4vD19eXhIQENm/efN72y5Yto3v37vj6+tKnTx9Wrlx5zrb33HMPJpOJOXPm1NkeFxeHyWSq83rxxReb4nQMkVlQDkBMqIbXRESkYSaTiVm39qF9mD/HT5dx/+JtWkTyPC4pIKWnp3P8+HH7z5s3b+ahhx5iwYIFF3WcpUuXkpyczFNPPcW2bduIj48nKSmJ7OzsBttv3LiR8ePHM2XKFLZv387o0aMZPXo0e/bsOavtJ598wjfffENMTEyDx3r22WfJyMiwv6ZNm3ZRtbuS2rsSIgJ9DK5ERERcWbCvF3+dMAB/bw/WH8zlDx/v0qTtc7ikgPSb3/yGNWvWAJCZmckvf/lLNm/ezBNPPMGzzz7b6OO8+uqrTJ06lcmTJ9OzZ0/mz5+Pv78/77zzToPtX3vtNUaOHMn06dPp0aMHzz33HAMGDGDu3Ll12p04cYJp06axaNEivLy8GjxWUFAQUVFR9ldAQECj63Y1OQpIIiLSSL3bhvDXCQPwNJv4ZPsJXvp8n9EluaRLCkh79uxhyJAhAHz44Yf07t2bjRs3smjRIt59991GHaOyspK0tDQSExN/LMZsJjExkdTU1Ab3SU1NrdMeICkpqU57q9XKHXfcwfTp0+nVq9c5P//FF18kPDyc/v378/LLL1NdXX3eeisqKigsLKzzchWnimseRhge6G1wJSIi4g6u6daGF2/rC8Dfv/qBd74+bHBFrsfzUnaqqqrCx6emt+KLL77gpptuAqB79+5kZGQ06hi5ublYLBYiIyPrbI+MjGTfvobTbGZmZoPtMzMz7T+/9NJLeHp68sADD5zzsx944AEGDBhAWFgYGzduZMaMGWRkZPDqq6+ec59Zs2bxzDPPNObUnK52iK21epBERKSRfj2wHVmF5bz8+X6e+/d3tAn24Vd9G56W0hJdUkDq1asX8+fPZ9SoUaxevZrnnnsOgJMnTxIeHt6kBV6MtLQ0XnvtNbZt24bJdO67uZKTk+3/3rdvX7y9vbn77ruZNWuWPfjVN2PGjDr7FRYWEhsb23TFXwb7HKQg9SCJiEjj/e6aK8guLGdh6lGSl+4kOsSPgR1aGV2WS7ikIbaXXnqJv//971xzzTWMHz+e+Ph4AD777DP70NuFRERE4OHhQVZWVp3tWVlZREVFNbhPVFTUeduvX7+e7Oxs2rdvj6enJ56enhw9epRHHnmEuLi4c9aSkJBAdXU1R44cOWcbHx8fgoOD67xcRe0Qm+YgiYjIxTCZTMy8sRcjekZSabFy9/tbOXFm4eGW7pIC0jXXXENubi65ubl1JlTfddddzJ8/v1HH8Pb2ZuDAgaSkpNi3Wa1WUlJSGDp0aIP7DB06tE57gNWrV9vb33HHHezatYsdO3bYXzExMUyfPp3PP//8nLXs2LEDs9lMmzZtGlW7K7HZbD+Zg6SAJCIiF8fDbOIvY/vRIzqY3OJKpi7cSmnl+efltgSXNMRWVlaGzWajVauabrijR4/yySef0KNHD5KSkhp9nOTkZCZNmsSgQYMYMmQIc+bMoaSkhMmTJwMwceJE2rZty6xZswB48MEHGT58OLNnz2bUqFEsWbKErVu32pcXCA8PP2uIz8vLi6ioKLp16wbUTPTetGkT1157LUFBQaSmpvLwww/z29/+1n4+7qSwrJpKS806FuEBGmITEZGLF+DjyZsTBzJ63ga+yygkeelO/jphQItefPiSepBuvvlm3nvvPQDy8/NJSEhg9uzZjB49mr/97W+NPs7YsWN55ZVXmDlzJv369WPHjh2sWrXKPhH72LFjdSZ9Dxs2jMWLF7NgwQLi4+P56KOPWL58Ob179270Z/r4+LBkyRKGDx9Or169eP7553n44Ycveg0nV5FbUjP/KMjXE18vD4OrERERd9WulT9/v2Mg3h5mVn2byZwvDhhdkqFMNpvtoleIioiI4KuvvqJXr1689dZbvPHGG2zfvp2PP/6YmTNnsnfvXkfU6lIKCwsJCQmhoKDA0PlIm344xdgF39AxIoA1j15jWB0iItI8LNuazvSPdgEw9zf9m92dbY39/r6kHqTS0lKCgoIA+O9//8utt96K2Wzmyiuv5OjRo5dWsVySXPsEbQ2viYjI5bt9UCxTr+oIwB8+2sXh3BKDKzLGJQWkzp07s3z5ctLT0/n8888ZMWIEANnZ2S51d1dLcKpEq2iLiEjT+sPI7gyJC6Ok0sLvFm2jvMpidElOd0kBaebMmTz66KPExcUxZMgQ+11k//3vf+nfv3+TFijnl1tUE5C0iraIiDQVTw8zr4/vT3iAN3szCnluxXdGl+R0lxSQfv3rX3Ps2DG2bt1a5/b56667jr/85S9NVpxcWI7WQBIREQeICvHlL2P7YTLBok3H+GznSaNLcqpLCkhQs2hj//79OXnyJMePHwdgyJAhdO/evcmKkws7pQfVioiIg1zdtTX3XdMZgBkft6z5SJcUkKxWK88++ywhISF06NCBDh06EBoaynPPPYfVam3qGuU87I8Z0RCbiIg4wEOJXRjSsWY+0j3vp3Gyhay0fUkB6YknnmDu3Lm8+OKLbN++ne3bt/PCCy/wxhtv8Mc//rGpa5TzyNUQm4iIOJCnh5k3xvcnItCb/VlF3PD6elL2Zl14Rzd3SesgxcTEMH/+fG666aY62z/99FN+97vfceLEiSYr0FW5yjpIvWauoqTSwtpHryEuIsCwOkREpHk7dqqU+xZvY/eJAgDuuroT05O64eVxybN1DOHQdZDy8vIanGvUvXt38vLyLuWQcgnKKi2UVNbceqm72ERExJHah/vz0b1DuXNYHAAL1v3AmL+nNtsht0sKSPHx8cydO/es7XPnzqVv376XXZQ0Tu38Ix9PM4E+l/RYPRERkUbz8fTg6Zt6Mf+3Awjy9WT7sXxu+esG9mcWGV1ak7ukb9U///nPjBo1ii+++MK+BlJqairp6emsXLmySQuUc8v9yR1sJlPLfaCgiIg418je0fSKCWHyu1s4lF3M7fM38takwQzpGGZ0aU3mknqQhg8fzoEDB7jlllvIz88nPz+fW2+9lW+//Zb333+/qWuUc9BjRkRExCixYf58dM9QBrQPpbC8mjve3sR/v800uqwmc0mTtM9l586dDBgwAIul+S9J7gqTtD/YfIwZ/9rNdd3b8Padgw2pQUREWraySgvTPtjGF3uzMZvg+Vv6MH5Ie6PLOieHTtIW16BFIkVExGh+3h7M/+1Axg6KxWqDGf/azfqDOUaXddkUkNxY7RCb7mATEREjeXqYefG2PowbHAvAo8t2crqk0uCqLo8CkhvLUQ+SiIi4CJPJxFM39uKK1gFkFVYw41+7acJZPE53UXex3Xrrred9Pz8//3JqkYtkH2ILUkASERHj+Xl78Nq4/tzy1w2s+jaTZVuPM+ZMr5K7uaiAFBIScsH3J06ceFkFSePZ72IL0BCbiIi4ht5tQ0j+ZTdeWrWPp//vWwZ3DKOjGz7p4aIC0j/+8Q9H1SGXIFc9SCIi4oLuuroTa/dns+lwHg8t3cFH9wx1u0eSuFe1YldlsZJfWgVoDpKIiLgWD7OJV8f2I8jXk53p+Ty34ju3m4+kgOSm8s7cHeBhNhHq52VwNSIiInW1DfXjxVtrHj/2XupRnvk/9wpJCkhuKqeoZngtLMAbs1mPGREREdczqm80L97aB5MJ3t14hJmffovV6h4hSQHJTZ0qqX3MiIbXRETEdY0b0p6XbuuLyQTvf3OUJz/d4xYhSQHJTeUW1a6BpDvYRETEtY0ZFMvLv47HZILFm47xxPLdLh+SFJDcVK4WiRQRETfy64HtmH17PGYTfLA5ncf+tculQ5ICkpv6cYhNPUgiIuIebh3Qjr+M7YfZBB9uPc70j3ZhcdGQpIDkpn4cYlMPkoiIuI+b+7XltXH98TCb+HjbcR75cAfVFqvRZZ1FAclN1T6HLVwBSURE3MyN8THMHd8fT7OJ5TtO8vCHO10uJCkgualTxRpiExER93V9n2jmTRiAl4eJ/9tZE5JcabhNAclNaZK2iIi4u6ReUfxtwkB7SPr9R64zcVsByQ1ZrTatgyQiIs1CYs9I3hj/45ykP366xyVW3FZAckMFZVX2bshwDbGJiIibG9k7mlfH1KyTtGjTMf70772GhyQFJDdUO7wW6u/ldk9HFhERacjN/dry0plnt7399WFe+e9+Q+vRt6sbst/BFqDeIxERaT7GDI7l2Zt7ATBvzfes3J1hWC2ehn2yXLIf72DT/CMREWleJg6No6LKyncZhYzoGWlYHQpIbsh+B1uQApKIiDQ/U6/uhM1mw2QyGVaDhtjckD0gaYhNRESaKSPDESgguSUNsYmIiDiWApIb0hCbiIiIYykguaGcMz1IuotNRETEMRSQ3NDpM6toa5FIERERx1BAckMFZVUAhPgpIImIiDiCApKbsVhtFJbXBKRQfy+DqxEREWmeFJDcTFF5FbWPpwnxU0ASERFxBAUkN5NfWtN7FOjjqeewiYiIOIi+Yd1Mvn3+kXqPREREHEUByc3kl9bcwab5RyIiIo6jgORmCtSDJCIi4nAKSG6mNiCpB0lERMRxDA9I8+bNIy4uDl9fXxISEti8efN52y9btozu3bvj6+tLnz59WLly5Tnb3nPPPZhMJubMmVNne15eHhMmTCA4OJjQ0FCmTJlCcXFxU5yOw9VO0tYaSCIiIo5jaEBaunQpycnJPPXUU2zbto34+HiSkpLIzs5usP3GjRsZP348U6ZMYfv27YwePZrRo0ezZ8+es9p+8sknfPPNN8TExJz13oQJE/j2229ZvXo1K1asYN26ddx1111Nfn6OUBuQ1IMkIiLiOIYGpFdffZWpU6cyefJkevbsyfz58/H39+edd95psP1rr73GyJEjmT59Oj169OC5555jwIABzJ07t067EydOMG3aNBYtWoSXV90gsXfvXlatWsVbb71FQkICP//5z3njjTdYsmQJJ0+edNi5NpX8sjOTtDUHSURExGEMC0iVlZWkpaWRmJj4YzFmM4mJiaSmpja4T2pqap32AElJSXXaW61W7rjjDqZPn06vXr0aPEZoaCiDBg2yb0tMTMRsNrNp06Zz1ltRUUFhYWGdlxEK1IMkIiLicIYFpNzcXCwWC5GRkXW2R0ZGkpmZ2eA+mZmZF2z/0ksv4enpyQMPPHDOY7Rp06bONk9PT8LCws75uQCzZs0iJCTE/oqNjT3v+TlKvp7DJiIi4nCGT9JuSmlpabz22mu8++67mEymJj32jBkzKCgosL/S09Ob9PiNVbsOkm7zFxERcRzDAlJERAQeHh5kZWXV2Z6VlUVUVFSD+0RFRZ23/fr168nOzqZ9+/Z4enri6enJ0aNHeeSRR4iLi7Mfo/4k8OrqavLy8s75uQA+Pj4EBwfXeRmhoKwa0BCbiIiIIxkWkLy9vRk4cCApKSn2bVarlZSUFIYOHdrgPkOHDq3THmD16tX29nfccQe7du1ix44d9ldMTAzTp0/n888/tx8jPz+ftLQ0+zG+/PJLrFYrCQkJTX2aTcpms1FQppW0RUREHM3TyA9PTk5m0qRJDBo0iCFDhjBnzhxKSkqYPHkyABMnTqRt27bMmjULgAcffJDhw4cze/ZsRo0axZIlS9i6dSsLFiwAIDw8nPDw8Dqf4eXlRVRUFN26dQOgR48ejBw5kqlTpzJ//nyqqqq4//77GTduXINLAriS0koLVRYbAKGagyQiIuIwhgaksWPHkpOTw8yZM8nMzKRfv36sWrXKPhH72LFjmM0/dnINGzaMxYsX8+STT/L444/TpUsXli9fTu/evS/qcxctWsT999/Pddddh9ls5rbbbuP1119v0nNzhNoJ2t6eZny9mtX0MREREZdistlsNqOLcEeFhYWEhIRQUFDgtPlI354sYNTrX9MmyIfNTyReeAcRERGpo7Hf3+qGcCNaA0lERMQ5FJDcyI9rICkgiYiIOJICkhsp0CKRIiIiTqGA5Eb0oFoRERHnUEByI3pQrYiIiHMoILkRTdIWERFxDgUkN1I7xBbirzlIIiIijqSA5EY0xCYiIuIcCkhuxN6DpIAkIiLiUApIbqSwTHOQREREnEEByY3ULhSpB9WKiIg4lgKSm6iotlBaaQEgRD1IIiIiDqWA5CZqV9E2myDIx9PgakRERJo3BSQ3UfCTCdpms8ngakRERJo3BSQ3YZ9/pDWQREREHE4ByU3U3uIfrFv8RUREHE4ByU3kl2qRSBEREWdRQHITBVoDSURExGkUkNyEPSCpB0lERMThFJDchB5UKyIi4jwKSG4iXz1IIiIiTqOA5Cbsk7Q1B0lERMThFJDcRO0cpBD1IImIiDicApKbqJ2DpB4kERERx1NAchM/9iBpkraIiIijKSC5AYvVRmG5epBEREScRQHJDRSVV2Gz1fy75iCJiIg4ngKSG6idfxTo44mXh/7IREREHE3ftm4gX3ewiYiIOJUCkhuoXQNJAUlERMQ5FJDcgB5UKyIi4lwKSG5AAUlERMS5FJDcgP1BtVoDSURExCkUkNyAVtEWERFxLgUkN5BfduZBtZqkLSIi4hQKSG6goFS3+YuIiDiTApIbyNckbREREadSQHIDP66DpEnaIiIizqCA5AYKyqoB9SCJiIg4iwKSi7PZbBTUTtJWQBIREXEKBSQXV1ppocpiAyBUQ2wiIiJOoYDk4monaHt7mvH10h+XiIiIM+gb18X99EG1JpPJ4GpERERaBgUkF1e7BpIWiRQREXEeBSQXpzWQREREnE8BycUVlOlBtSIiIs6mgOTi9KBaERER51NAcnF6UK2IiIjzGR6Q5s2bR1xcHL6+viQkJLB58+bztl+2bBndu3fH19eXPn36sHLlyjrvP/3003Tv3p2AgABatWpFYmIimzZtqtMmLi4Ok8lU5/Xiiy82+bk1hQL1IImIiDidoQFp6dKlJCcn89RTT7Ft2zbi4+NJSkoiOzu7wfYbN25k/PjxTJkyhe3btzN69GhGjx7Nnj177G26du3K3Llz2b17N19//TVxcXGMGDGCnJycOsd69tlnycjIsL+mTZvm0HO9VLVDbCHqQRIREXEak81msxn14QkJCQwePJi5c+cCYLVaiY2NZdq0aTz22GNntR87diwlJSWsWLHCvu3KK6+kX79+zJ8/v8HPKCwsJCQkhC+++ILrrrsOqOlBeuihh3jooYcuufba4xYUFBAcHHzJx7mQcQtS+eaHPF4f35+b4mMc9jkiIiItQWO/vw3rQaqsrCQtLY3ExMQfizGbSUxMJDU1tcF9UlNT67QHSEpKOmf7yspKFixYQEhICPHx8XXee/HFFwkPD6d///68/PLLVFdXn7feiooKCgsL67ycIV/rIImIiDidp1EfnJubi8ViITIyss72yMhI9u3b1+A+mZmZDbbPzMyss23FihWMGzeO0tJSoqOjWb16NREREfb3H3jgAQYMGEBYWBgbN25kxowZZGRk8Oqrr56z3lmzZvHMM89c7GletkKtgyQiIuJ0hgUkR7r22mvZsWMHubm5vPnmm4wZM4ZNmzbRpk0bAJKTk+1t+/bti7e3N3fffTezZs3Cx8enwWPOmDGjzn6FhYXExsY69kT4yUKRWgdJRETEaQwbYouIiMDDw4OsrKw627OysoiKimpwn6ioqEa1DwgIoHPnzlx55ZW8/fbbeHp68vbbb5+zloSEBKqrqzly5Mg52/j4+BAcHFzn5WgV1RZKKy0AhKgHSURExGkMC0je3t4MHDiQlJQU+zar1UpKSgpDhw5tcJ+hQ4fWaQ+wevXqc7b/6XErKirO+f6OHTswm832HiZXUbuKttkEQT7NsrNPRETEJRn6rZucnMykSZMYNGgQQ4YMYc6cOZSUlDB58mQAJk6cSNu2bZk1axYADz74IMOHD2f27NmMGjWKJUuWsHXrVhYsWABASUkJzz//PDfddBPR0dHk5uYyb948Tpw4we233w7UTPTetGkT1157LUFBQaSmpvLwww/z29/+llatWhlzIc6hdg2kYD8vzGaTwdWIiIi0HIYGpLFjx5KTk8PMmTPJzMykX79+rFq1yj4R+9ixY5jNP3ZyDRs2jMWLF/Pkk0/y+OOP06VLF5YvX07v3r0B8PDwYN++fSxcuJDc3FzCw8MZPHgw69evp1evXkDNUNmSJUt4+umnqaiooGPHjjz88MN15he5ih/nH2l4TURExJkMXQfJnTljHaTV32Ux9b2txMeG8ul9P3PIZ4iIiLQkLr8OklxYgXqQREREDKGA5MLyS888qFZ3sImIiDiVApILUw+SiIiIMRSQXJj9QbX+WiRSRETEmRSQXFjtXWwh6kESERFxKgUkF2afg6SAJCIi4lQKSC6sQA+qFRERMYQCkgurnYOkgCQiIuJcCkgurMA+B0mTtEVERJxJAclFWaw2CsvVgyQiImIEBSQXVVReRe1DYHQXm4iIiHMpILmo2vlHAd4eeHnoj0lERMSZ9M3rovLtd7Bp/pGIiIizKSC5qNo1kDS8JiIi4nwKSC5KayCJiIgYRwHJRSkgiYiIGEcByUXZH1SrNZBEREScTgHJRWkVbREREeMoILmo/DJN0hYRETGKApKLKqjtQVJAEhERcToFJBeVr0naIiIihlFAclE/roOkSdoiIiLOpoDkogrKqgH1IImIiBhBAckF2Ww2Cs5M0lZAEhERcT4FJBdUWmmhymIDIFRDbCIiIk6ngOSCaidoe3uY8fXSH5GIiIiz6dvXBdknaPt7YTKZDK5GRESk5VFAckFaA0lERMRYCkguSGsgiYiIGEsByQUVlOlBtSIiIkZSQHJBelCtiIiIsRSQXFDtg2o1B0lERMQYCkguqHaSdogCkoiIiCEUkFyQhthERESMpYDkgmqH2EL8NUlbRETECApILihf6yCJiIgYSgHJBRVqHSQRERFDKSC5IPtCkVoHSURExBAKSC6motpCaaUF0F1sIiIiRlFAcjG1q2ibTBDk62lwNSIiIi2TApKL+ekaSGazyeBqREREWiYFJBfz4/wjDa+JiIgYRQHJxdTe4q81kERERIyjgORiCtSDJCIiYjgFJBeTX3rmQbVaA0lERMQwCkguprYHSbf4i4iIGEcBycXoMSMiIiLGU0ByMbV3sWmStoiIiHEMD0jz5s0jLi4OX19fEhIS2Lx583nbL1u2jO7du+Pr60ufPn1YuXJlnfeffvppunfvTkBAAK1atSIxMZFNmzbVaZOXl8eECRMIDg4mNDSUKVOmUFxc3OTndinsc5DUgyQiImIYQwPS0qVLSU5O5qmnnmLbtm3Ex8eTlJREdnZ2g+03btzI+PHjmTJlCtu3b2f06NGMHj2aPXv22Nt07dqVuXPnsnv3br7++mvi4uIYMWIEOTk59jYTJkzg22+/ZfXq1axYsYJ169Zx1113Ofx8G6NAD6oVERExnMlms9mM+vCEhAQGDx7M3LlzAbBarcTGxjJt2jQee+yxs9qPHTuWkpISVqxYYd925ZVX0q9fP+bPn9/gZxQWFhISEsIXX3zBddddx969e+nZsydbtmxh0KBBAKxatYobbriB48ePExMT06jaa49bUFBAcHDwxZ76OQ1/eQ1HT5Xy8b1DGdghrMmOKyIiIo3//jasB6myspK0tDQSExN/LMZsJjExkdTU1Ab3SU1NrdMeICkp6ZztKysrWbBgASEhIcTHx9uPERoaag9HAImJiZjN5rOG4n6qoqKCwsLCOi9HeOrGnrx0Wx86RgQ65PgiIiJyYYY9DTU3NxeLxUJkZGSd7ZGRkezbt6/BfTIzMxtsn5mZWWfbihUrGDduHKWlpURHR7N69WoiIiLsx2jTpk2d9p6enoSFhZ11nJ+aNWsWzzzzTKPP71L9onvkhRuJiIiIQxk+SdsRrr32Wnbs2MHGjRsZOXIkY8aMOee8psaaMWMGBQUF9ld6enoTVSsiIiKuxrCAFBERgYeHB1lZWXW2Z2VlERUV1eA+UVFRjWofEBBA586dufLKK3n77bfx9PTk7bffth+jfliqrq4mLy/vnJ8L4OPjQ3BwcJ2XiIiINE+GBSRvb28GDhxISkqKfZvVaiUlJYWhQ4c2uM/QoUPrtAdYvXr1Odv/9LgVFRX2Y+Tn55OWlmZ//8svv8RqtZKQkHCppyMiIiLNiGFzkACSk5OZNGkSgwYNYsiQIcyZM4eSkhImT54MwMSJE2nbti2zZs0C4MEHH2T48OHMnj2bUaNGsWTJErZu3cqCBQsAKCkp4fnnn+emm24iOjqa3Nxc5s2bx4kTJ7j99tsB6NGjByNHjmTq1KnMnz+fqqoq7r//fsaNG9foO9hERESkeTM0II0dO5acnBxmzpxJZmYm/fr1Y9WqVfaJ2MeOHcNs/rGTa9iwYSxevJgnn3ySxx9/nC5durB8+XJ69+4NgIeHB/v27WPhwoXk5uYSHh7O4MGDWb9+Pb169bIfZ9GiRdx///1cd911mM1mbrvtNl5//XXnnryIiIi4LEPXQXJnjloHSURERBzH5ddBEhEREXFVCkgiIiIi9SggiYiIiNSjgCQiIiJSjwKSiIiISD0KSCIiIiL1KCCJiIiI1GPoQpHurHb5qMLCQoMrERERkcaq/d6+0DKQCkiXqKioCIDY2FiDKxEREZGLVVRUREhIyDnf10ral8hqtXLy5EmCgoIYMmQIW7ZsOavN4MGDz9p+oW2FhYXExsaSnp7ulBW6G6rHUfs3pu352pzrvcZuN/I6n69OR+x7ofaX+n5jfqfr/6zf6ab5ndbfHbrOjt6/pVxnm81GUVERMTExdR5nVp96kC6R2WymXbt2QM0z4Br6A2xoe2O3BQcHO+U/vnPV7oj9G9P2fG0u5jo3tN3I63yuz3fUvhdqf6nvN+b391z76ne68e/p746Lb6vrfPn7t6TrfL6eo1qapN0E7rvvvkZvb+w2Z7ncz76Y/RvT9nxtLuY6N7TdyOt8uZ9/sfteqP2lvt+Y3193vs4Xu78zf6f1d8elt9F1brq2zfU6N0RDbC5GD8F1Dl1n59G1dg5dZ+fQdXYOV7jO6kFyMT4+Pjz11FP4+PgYXUqzpuvsPLrWzqHr7By6zs7hCtdZPUgiIiIi9agHSURERKQeBSQRERGRehSQREREROpRQBIRERGpRwFJREREpB4FJDd2+PBhrr32Wnr27EmfPn0oKSkxuqRmKy4ujr59+9KvXz+uvfZao8tp1kpLS+nQoQOPPvqo0aU0S/n5+QwaNIh+/frRu3dv3nzzTaNLapbS09O55ppr6NmzJ3379mXZsmVGl9Ss3XLLLbRq1Ypf//rXTXZM3ebvxoYPH86f/vQnrrrqKvLy8ggODsbTU0+PcYS4uDj27NlDYGCg0aU0e0888QSHDh0iNjaWV155xehymh2LxUJFRQX+/v6UlJTQu3dvtm7dSnh4uNGlNSsZGRlkZWXRr18/MjMzGThwIAcOHCAgIMDo0pqltWvXUlRUxMKFC/noo4+a5JjqQXJT3377LV5eXlx11VUAhIWFKRyJ2zt48CD79u3j+uuvN7qUZsvDwwN/f38AKioqsNls6P+Tm150dDT9+vUDICoqioiICPLy8owtqhm75pprCAoKatJjKiA5yLp167jxxhuJiYnBZDKxfPnys9rMmzePuLg4fH19SUhIYPPmzY0+/sGDBwkMDOTGG29kwIABvPDCC01YvXtx9LUGMJlMDB8+nMGDB7No0aImqty9OOM6P/roo8yaNauJKnZPzrjO+fn5xMfH065dO6ZPn05EREQTVe8+nHGda6WlpWGxWIiNjb3Mqt2TM691U1JAcpCSkhLi4+OZN29eg+8vXbqU5ORknnrqKbZt20Z8fDxJSUlkZ2fb29TOEaj/OnnyJNXV1axfv56//vWvpKamsnr1alavXu2s03Mpjr7WAF9//TVpaWl89tlnvPDCC+zatcsp5+ZKHH2dP/30U7p27UrXrl2ddUouyRm/z6GhoezcuZPDhw+zePFisrKynHJursQZ1xkgLy+PiRMnsmDBAoefk6ty1rVucjZxOMD2ySef1Nk2ZMgQ23333Wf/2WKx2GJiYmyzZs1q1DE3btxoGzFihP3nP//5z7Y///nPTVKvO3PEta7v0Ucftf3jH/+4jCrdnyOu82OPPWZr166drUOHDrbw8HBbcHCw7ZlnnmnKst2OM36f7733XtuyZcsup0y356jrXF5ebrvqqqts7733XlOV6vYc+Tu9Zs0a22233dYUZdpsNptNPUgGqKysJC0tjcTERPs2s9lMYmIiqampjTrG4MGDyc7O5vTp01itVtatW0ePHj0cVbLbaoprXVJSQlFREQDFxcV8+eWX9OrVyyH1uqumuM6zZs0iPT2dI0eO8MorrzB16lRmzpzpqJLdUlNc56ysLPvvc0FBAevWraNbt24OqdddNcV1ttls3HnnnfziF7/gjjvucFSpbq8prrWjaFavAXJzc7FYLERGRtbZHhkZyb59+xp1DE9PT1544QWuvvpqbDYbI0aM4Fe/+pUjynVrTXGts7KyuOWWW4CaO4CmTp3K4MGDm7xWd9YU11kurCmu89GjR7nrrrvsk7OnTZtGnz59HFGu22qK67xhwwaWLl1K37597XNu3n//fV3reprq747ExER27txJSUkJ7dq1Y9myZQwdOvSyalNAcmPXX3+97vZxgk6dOrFz506jy2hR7rzzTqNLaLaGDBnCjh07jC6j2fv5z3+O1Wo1uowW44svvmjyY2qIzQARERF4eHicNTEyKyuLqKgog6pqnnStnUPX2Tl0nZ1D19l5XPlaKyAZwNvbm4EDB5KSkmLfZrVaSUlJuewuQalL19o5dJ2dQ9fZOXSdnceVr7WG2BykuLiYQ4cO2X8+fPgwO3bsICwsjPbt25OcnMykSZMYNGgQQ4YMYc6cOZSUlDB58mQDq3ZPutbOoevsHLrOzqHr7Dxue62b7H44qWPNmjU24KzXpEmT7G3eeOMNW/v27W3e3t62IUOG2L755hvjCnZjutbOoevsHLrOzqHr7Dzueq31LDYRERGRejQHSURERKQeBSQRERGRehSQREREROpRQBIRERGpRwFJREREpB4FJBEREZF6FJBERERE6lFAEhEREalHAUlEWqy4uDjmzJljdBki4oK0kraIONSdd95Jfn4+y5cvN7qUs+Tk5BAQEIC/v7/RpTTIla+dSHOnHiQRaXaqqqoa1a5169aGhKPG1icixlFAEhFD7dmzh+uvv57AwEAiIyO54447yM3Ntb+/atUqfv7znxMaGkp4eDi/+tWv+P777+3vHzlyBJPJxNKlSxk+fDi+vr4sWrSIO++8k9GjR/PKK68QHR1NeHg49913X51wUn+IzWQy8dZbb3HLLbfg7+9Ply5d+Oyzz+rU+9lnn9GlSxd8fX259tprWbhwISaTifz8/HOeo8lk4m9/+xs33XQTAQEBPP/881gsFqZMmULHjh3x8/OjW7duvPbaa/Z9nn76aRYuXMinn36KyWTCZDKxdu1aANLT0xkzZgyhoaGEhYVx8803c+TIkUv7AxCRBikgiYhh8vPz+cUvfkH//v3ZunUrq1atIisrizFjxtjblJSUkJyczNatW0lJScFsNnPLLbdgtVrrHOuxxx7jwQcfZO/evSQlJQGwZs0avv/+e9asWcPChQt59913effdd89b0zPPPMOYMWPYtWsXN9xwAxMmTCAvLw+Aw4cP8+tf/5rRo0ezc+dO7r77bp544olGnevTTz/NLbfcwu7du/mf//kfrFYr7dq1Y9myZXz33XfMnDmTxx9/nA8//BCARx99lDFjxjBy5EgyMjLIyMhg2LBhVFVVkZSURFBQEOvXr2fDhg0EBgYycuRIKisrG3vpReRCbCIiDjRp0iTbzTff3OB7zz33nG3EiBF1tqWnp9sA2/79+xvcJycnxwbYdu/ebbPZbLbDhw/bANucOXPO+twOHTrYqqur7dtuv/1229ixY+0/d+jQwfaXv/zF/jNge/LJJ+0/FxcX2wDbf/7zH5vNZrP94Q9/sPXu3bvO5zzxxBM2wHb69OmGL8CZ4z700EPnfL/WfffdZ7vtttvqnEP9a/f+++/bunXrZrNarfZtFRUVNj8/P9vnn39+wc8QkcZRD5KIGGbnzp2sWbOGwMBA+6t79+4A9mG0gwcPMn78eDp16kRwcDBxcXEAHDt2rM6xBg0adNbxe/XqhYeHh/3n6OhosrOzz1tT37597f8eEBBAcHCwfZ/9+/czePDgOu2HDBnSqHNtqL558+YxcOBAWrduTWBgIAsWLDjrvOrbuXMnhw4dIigoyH7NwsLCKC8vrzP0KCKXx9PoAkSk5SouLubGG2/kpZdeOuu96OhoAG688UY6dOjAm2++SUxMDFarld69e581nBQQEHDWMby8vOr8bDKZzhqaa4p9GqN+fUuWLOHRRx9l9uzZDB06lKCgIF5++WU2bdp03uMUFxczcOBAFi1adNZ7rVu3vuw6RaSGApKIGGbAgAF8/PHHxMXF4el59l9Hp06dYv/+/bz55ptcddVVAHz99dfOLtOuW7durFy5ss62LVu2XNKxNmzYwLBhw/jd735n31a/B8jb2xuLxVJn24ABA1i6dClt2rQhODj4kj5bRC5MQ2wi4nAFBQXs2LGjzis9PZ377ruPvLw8xo8fz5YtW/j+++/5/PPPmTx5MhaLhVatWhEeHs6CBQs4dOgQX375JcnJyYadx913382+ffv4wx/+wIEDB/jwww/tk75NJtNFHatLly5s3bqVzz//nAMHDvDHP/7xrLAVFxfHrl272L9/P7m5uVRVVTFhwgQiIiK4+eabWb9+PYcPH2bt2rU88MADHD9+vKlOVaTFU0ASEYdbu3Yt/fv3r/N65plniImJYcOGDVgsFkaMGEGfPn146KGHCA0NxWw2YzabWbJkCWlpafTu3ZuHH36Yl19+2bDz6NixIx999BH/+te/6Nu3L3/729/sd7H5+Phc1LHuvvtubr31VsaOHUtCQgKnTp2q05sEMHXqVLp168agQYNo3bo1GzZswN/fn3Xr1tG+fXtuvfVWevTowZQpUygvL1ePkkgT0kraIiKX4fnnn2f+/Pmkp6cbXYqINCHNQRIRuQh//etfGTx4MOHh4WzYsIGXX36Z+++/3+iyRKSJKSCJiFyEgwcP8qc//Ym8vDzat2/PI488wowZM4wuS0SamIbYREREROrRJG0RERGRehSQREREROpRQBIRERGpRwFJREREpB4FJBEREZF6FJBERERE6lFAEhEREalHAUlERESkHgUkERERkXr+H3J3UhaRG81QAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# learning rate optimization\n",
    "lr_tuner = Tuner(lr_trainer).lr_find(\n",
    "    tft_tuner,\n",
    "    train_dataloaders = train_dataloader,\n",
    "    val_dataloaders = val_dataloader,\n",
    "    max_lr = 0.1,\n",
    "    min_lr = 1e-6,\n",
    ")\n",
    "\n",
    "print(f\"suggested learning rate: {lr_tuner.suggestion()}\")\n",
    "fig = lr_tuner.plot(show=True, suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00f75789",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 5.267k\n"
     ]
    }
   ],
   "source": [
    "#set up trainer for training\n",
    "logger = TensorBoardLogger(save_dir = \"\", version = \"train\")  # logging results to the current pwd\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\", min_delta=1e-4, patience=10, mode=\"min\"\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator = \"gpu\",\n",
    "    devices = \"auto\",\n",
    "    gradient_clip_val = 0.1,\n",
    "    #fast_dev_run=True,  # comment in for debugging, only 1 training and 1 validation batch to run\n",
    "    callbacks=[early_stop_callback],\n",
    "    logger = logger,\n",
    ")\n",
    "\n",
    "#set up tft for taining\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    train_dataset,\n",
    "    # not meaningful for finding the learning rate but otherwise very important\n",
    "    learning_rate = lr_tuner.suggestion(),\n",
    "    hidden_size = 8,  # most important hyperparameter apart from learning rate\n",
    "    # number of attention heads. Set to up to 4 for large datasets\n",
    "    attention_head_size = 2,\n",
    "    lstm_layers = 2,  # set to 2 or 3 for large datasets\n",
    "    dropout = 0.1,  # between 0.1 and 0.3 are good values\n",
    "    loss = QuantileLoss(),\n",
    "    reduce_on_plateau_patience = 100\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size() / 1e3:.3f}k\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "611c5baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 0      | train\n",
      "3  | prescalers                         | ModuleDict                      | 16     | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 0      | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 320    | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 0      | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 304    | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 304    | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 304    | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 304    | train\n",
      "11 | lstm_encoder                       | LSTM                            | 1.2 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 1.2 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 144    | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 16     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 368    | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 212    | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 160    | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 304    | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 160    | train\n",
      "20 | output_layer                       | Linear                          | 63     | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "5.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.3 K     Total params\n",
      "0.021     Total estimated model params size (MB)\n",
      "124       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 1/1 [00:01<00:00,  0.81it/s, v_num=rain, train_loss_step=0.0225, val_loss=0.0044, train_loss_epoch=0.0225] \n"
     ]
    }
   ],
   "source": [
    "# fit network\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders = train_dataloader,\n",
    "    val_dataloaders = val_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aac690",
   "metadata": {},
   "source": [
    "#open tensorboard to check the results\n",
    "tb = program.TensorBoard()\n",
    "tb.configure(argv=[None, '--logdir', 'lightning_logs', '--port', '6006'])\n",
    "print(\"TensorBoard running at http://localhost:6006/\")\n",
    "tb.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68297b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the best model according to the validation loss from training log\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cec186c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  3.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_MAE          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.008423394523561     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_MAPE          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.008875485509634018    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_RMSE          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.010106625035405159    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_SMAPE         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.008933818899095058    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.00440498860552907    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_MAE         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.008423394523561    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_MAPE         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.008875485509634018   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_RMSE         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.010106625035405159   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_SMAPE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.008933818899095058   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.00440498860552907   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.00440498860552907,\n",
       "  'val_SMAPE': 0.008933818899095058,\n",
       "  'val_MAE': 0.008423394523561,\n",
       "  'val_RMSE': 0.010106625035405159,\n",
       "  'val_MAPE': 0.008875485509634018}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the metrics on val_dataset\n",
    "trainer.validate(best_tft, dataloaders=val_dataloader)#, ckpt_path=best_model_path)\n",
    "#the \"ckpt_path\" argument is not necessary, but it is good practice to load the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934813e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  3.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_MAE          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.024220434948801994    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_MAPE         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.025577636435627937    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_RMSE         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.02574038691818714    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_SMAPE         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.025208670645952225    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.021505530923604965    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_MAE         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.024220434948801994   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_MAPE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.025577636435627937   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_RMSE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.02574038691818714   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_SMAPE        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.025208670645952225   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.021505530923604965   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.021505530923604965,\n",
       "  'test_SMAPE': 0.025208670645952225,\n",
       "  'test_MAE': 0.024220434948801994,\n",
       "  'test_RMSE': 0.02574038691818714,\n",
       "  'test_MAPE': 0.025577636435627937}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluation on test set\n",
    "trainer.test(best_tft, dataloaders=test_dataloader)#, ckpt_path=best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00522c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "test_pred_x_raw = best_tft.predict(test_dataloader, mode=\"raw\", return_x=True, return_y=True) #incldue the attension weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b21dd57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('output', 'x', 'index', 'decoder_lengths', 'y')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_x_raw.keys() #the outputs are quantile predictions comparing the single prediction of \"test_pred\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c3563d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('prediction',\n",
       " 'encoder_attention',\n",
       " 'decoder_attention',\n",
       " 'static_variables',\n",
       " 'encoder_variables',\n",
       " 'decoder_variables',\n",
       " 'decoder_lengths',\n",
       " 'encoder_lengths')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_x_raw.output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5707ca67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 2, 7])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_x_raw.output.prediction.shape #the quantile predictions, the median = test_pred.output\n",
    "#the \"output\" is a dictionary, the \"prediction\" is a tensor with the shape of (batch_size, prediction_length, num_quantiles)\n",
    "#the quantiles = [0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98] as defined in `pytorch_forecasting.metrics.quantile.QuantileLoss` source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "827304a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0256, device='cuda:0')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MAPE\n",
    "test_pred = best_tft.predict(test_dataloader, return_y=True) \n",
    "#the prediction tensor are in the \"output\" by the shape of [batch_size, prediction_length],\n",
    "#the predictions are the median of the quantile predictions\n",
    "\n",
    "MAPE()(test_pred.output, test_pred.y[0]) #same for other metrics, and results are same from the \"trainer.test/validate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a344d22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YES, the output is equal the median prediction\n"
     ]
    }
   ],
   "source": [
    "#to prove the predictions are the median of the quantile predictions form \"predict(mode=None)\"\n",
    "results = True\n",
    "for b in range(test_pred.output.shape[0]):\n",
    "    results_check = (test_pred_x_raw.output.prediction[b, :, 3] == test_pred.output[b,...]).all()\n",
    "if not results_check:\n",
    "    results = False\n",
    "    print(f\"NO, the output is not equal to the median prediction\")\n",
    "else:\n",
    "    print(f\"YES, the output is equal the median prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5722b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0256, device='cuda:0')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#help to scan the outliers of a metric\n",
    "apes = torch.abs((test_pred.output - test_pred.y[0]) / test_pred.y[0])\n",
    "print(apes.shape)\n",
    "apes.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c33b54",
   "metadata": {},
   "source": [
    "The above MAPE by hands result is expect to be same as function of `MAPE()`, but if the hand craft results a `inf`, then it may be caused by a `0` in the true value, and a zero corrector of `1e-8` is added by the `MAPE()` function in its source code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ea25665f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_apes = torch.abs((test_pred_x_raw.output.prediction[:,:,3] - test_pred_x_raw.y[0]) / test_pred_x_raw.y[0])\n",
    "sum(sum(_apes != apes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6ad25ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#locate the outliers in the result tensor\n",
    "def find_outlier_row_indices(tensor, threshold=2.0, method='zscore'):\n",
    "    \"\"\"\n",
    "    Identifies row indices containing outliers in a 2D PyTorch tensor.\n",
    "\n",
    "    Args:\n",
    "        tensor: A 2D PyTorch tensor.\n",
    "        threshold: The outlier detection threshold.\n",
    "        method: Method for outlier detection ('zscore' or 'iqr'). Defaults to 'zscore'.\n",
    "\n",
    "    Returns:\n",
    "        A tensor containing the unique row indices of the outliers.\n",
    "    \"\"\"\n",
    "    if method == 'zscore':\n",
    "        mean = torch.mean(tensor)\n",
    "        std = torch.std(tensor)\n",
    "        zscores = torch.abs((tensor - mean) / std)\n",
    "        outlier_mask = zscores > threshold\n",
    "    elif method == 'iqr':\n",
    "        q1 = torch.quantile(tensor.flatten(), 0.25)\n",
    "        q3 = torch.quantile(tensor.flatten(), 0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - threshold * iqr\n",
    "        upper_bound = q3 + threshold * iqr\n",
    "        outlier_mask = (tensor < lower_bound) | (tensor > upper_bound)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid method. Choose 'zscore' or 'iqr'.\")\n",
    "\n",
    "    outlier_indices = torch.nonzero(outlier_mask, as_tuple=False)\n",
    "\n",
    "    if outlier_indices.numel() == 0:  # Check if there are any outliers\n",
    "        return torch.empty(0, dtype=torch.long) # Return an empty tensor of Long type\n",
    "\n",
    "    outlier_rows = outlier_indices[:, 0]  # Extract row indices\n",
    "    unique_outlier_rows = torch.unique(outlier_rows)  # Get unique row indices\n",
    "\n",
    "    return unique_outlier_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "63138a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_sample = torch.tensor([[1,2],[3,4],[5,6],[7,8],[900,10]]).float()\n",
    "find_outlier_row_indices(outlier_sample, threshold=2.0, method='iqr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed8a86db",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_true = torch.stack([test_pred_x_raw.x[\"decoder_time_idx\"], test_pred_x_raw.y[0]], dim=2)\n",
    "stacked_true = stacked_true.reshape(-1, 2)\n",
    "stacked_true = stacked_true.unique(dim=0)\n",
    "print(stacked_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30fc6fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_check=stacked_true[:,1].reshape(-1,1).cpu() #the model is on \"GPU\" needs to be move to \"CPU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad7dc91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_val=torch.tensor(test_df[test_df[\"time_idx\"] >= 85][\"vals\"].values).unsqueeze(1)\n",
    "test_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "24054772",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_plot=torch.tensor(test_df[test_df[\"time_idx\"] >= 85][\"vals\"].values)\n",
    "test_plot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc77d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(test_val-stack_check) #the difference is caused by the \"TimeSeriesDataSet\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24be9346",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(test_val-test_pred_x_raw.y[0].reshape(-1, 1).unique(dim=0).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b0c3f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results plotting function\n",
    "def plot_single_timeseries_quantile_predictions(tensor1_preds, tensor2_actuals,\n",
    "                                                quantile_levels=None, quantile_labels=None,\n",
    "                                                title=\"Time Series Quantile Prediction\"):\n",
    "    \"\"\"\n",
    "    Plots quantile predictions (tensor1_preds) against actual values (tensor2_actuals)\n",
    "    for a single time series.\n",
    "\n",
    "    Args:\n",
    "        tensor1_preds (np.ndarray): Quantile predictions. Shape: [time, features].\n",
    "                                    Features are assumed to be sorted quantiles.\n",
    "                                    Example for 7 features: [q0.02, q0.1, q0.25, q0.5, q0.75, q0.9, q0.98]\n",
    "        tensor2_actuals (np.ndarray): Actual values. Shape: [time].\n",
    "        quantile_levels (list of float, optional): The actual quantile levels corresponding\n",
    "                                                   to the features in tensor1_preds.\n",
    "                                                   Used for generating accurate default labels.\n",
    "        quantile_labels (list of str, optional): Labels for the prediction intervals.\n",
    "                                                 If None, default labels will be generated.\n",
    "                                                 Order should correspond to outermost to innermost interval.\n",
    "        title (str, optional): The title for the plot.\n",
    "    \"\"\"\n",
    "    if tensor1_preds.ndim != 2:\n",
    "        raise ValueError(\"tensor1_preds (predictions) must be 2D [time, features].\")\n",
    "    if tensor2_actuals.ndim != 1:\n",
    "        raise ValueError(\"tensor2_actuals (actuals) must be 1D [time].\")\n",
    "    if tensor1_preds.shape[0] != tensor2_actuals.shape[0]:\n",
    "        raise ValueError(\"Time dimension of tensor1_preds and tensor2_actuals must match.\")\n",
    "\n",
    "    num_time_steps = tensor1_preds.shape[0]\n",
    "    num_features = tensor1_preds.shape[1]\n",
    "\n",
    "    if num_features % 2 == 0:\n",
    "        raise ValueError(\"Number of features in tensor1_preds must be odd to have a central median.\")\n",
    "    \n",
    "    median_index = num_features // 2\n",
    "\n",
    "    # Define quantile labels if not provided\n",
    "    if quantile_labels is None:\n",
    "        if num_features == 7 and quantile_levels and len(quantile_levels) == 7:\n",
    "            # Generate labels based on provided quantile_levels\n",
    "            # Assumes pairs are (0,6), (1,5), (2,4) for features\n",
    "            pi1_lower, pi1_upper = quantile_levels[0], quantile_levels[6]\n",
    "            pi2_lower, pi2_upper = quantile_levels[1], quantile_levels[5]\n",
    "            pi3_lower, pi3_upper = quantile_levels[2], quantile_levels[4]\n",
    "            \n",
    "            quantile_labels = [\n",
    "                f\"{(pi1_upper - pi1_lower) * 100:.0f}% PI ({pi1_lower:.2f}-{pi1_upper:.2f})\", # Outermost\n",
    "                f\"{(pi2_upper - pi2_lower) * 100:.0f}% PI ({pi2_lower:.2f}-{pi2_upper:.2f})\", # Middle\n",
    "                f\"{(pi3_upper - pi3_lower) * 100:.0f}% PI ({pi3_lower:.2f}-{pi3_upper:.2f})\"  # Innermost\n",
    "            ]\n",
    "        elif num_features == 7: # Default for 7 features if specific levels not given\n",
    "             quantile_labels = [\"96% PI (e.g., 0.02-0.98)\", \"80% PI (e.g., 0.1-0.9)\", \"50% PI (e.g., 0.25-0.75)\"]\n",
    "        else:\n",
    "            # Fallback for a different number of features\n",
    "            quantile_labels = [f\"Interval {i+1}\" for i in range(num_features // 2)]\n",
    "    \n",
    "    if len(quantile_labels) != num_features // 2:\n",
    "        raise ValueError(f\"Expected {num_features // 2} quantile labels, but got {len(quantile_labels)}.\")\n",
    "\n",
    "    # Set a nice seaborn style\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6)) # Single plot\n",
    "\n",
    "    time_indices = np.arange(num_time_steps)\n",
    "\n",
    "    # Plot actual values\n",
    "    ax.plot(time_indices, tensor2_actuals, label=\"Actual\", color=\"black\", marker='o', linestyle='-', zorder=num_features//2 + 2)\n",
    "\n",
    "    # Plot median prediction (middle feature)\n",
    "    median_prediction = tensor1_preds[:, median_index]\n",
    "    median_label_text = f\"Median ({quantile_levels[median_index]:.2f}Q)\" if quantile_levels and median_index < len(quantile_levels) else \"Median Prediction\"\n",
    "    ax.plot(time_indices, median_prediction, label=median_label_text, color=\"blue\", marker='x', linestyle='--', zorder=num_features//2 + 1)\n",
    "\n",
    "    # Plot prediction intervals\n",
    "    # Intervals are formed by pairing features from outside in\n",
    "    # e.g., for 7 features: (feature 0, feature 6), (feature 1, feature 5), (feature 2, feature 4)\n",
    "    # Colors for intervals - from lighter to darker for better visual hierarchy\n",
    "    # Using a list of distinct, visually pleasing colors for intervals\n",
    "    interval_palette = sns.color_palette(\"Blues\", n_colors=num_features // 2 + 2) # Get a few shades\n",
    "    \n",
    "    # The quantile_labels should be ordered from outermost to innermost.\n",
    "    # The loop for j goes from 0 (outermost interval) to (num_features // 2 - 1) (innermost interval).\n",
    "    for j in range(num_features // 2):\n",
    "        lower_quantile_idx = j\n",
    "        upper_quantile_idx = num_features - 1 - j\n",
    "        \n",
    "        # Assign colors such that the widest interval is lightest, narrowest is darkest within the theme\n",
    "        # So, interval_colors[j] means the j-th interval (0 = outermost) gets a progressively darker shade.\n",
    "        # The label quantile_labels[j] should correspond to this j-th interval.\n",
    "        ax.fill_between(time_indices, tensor1_preds[:, lower_quantile_idx], tensor1_preds[:, upper_quantile_idx],\n",
    "                        color=interval_palette[j], # interval_palette[0] is light, interval_palette[num_features//2 -1] is darker\n",
    "                        alpha=0.3 + (j * 0.1), # Alpha can also increase for inner bands if desired\n",
    "                        label=quantile_labels[j], \n",
    "                        zorder=j+1)\n",
    "\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Time Step\")\n",
    "    ax.set_ylabel(\"Value\")\n",
    "\n",
    "    if num_time_steps <= 20: # Show markers if not too many time steps\n",
    "        ax.set_xticks(time_indices)\n",
    "    else: # Otherwise, let matplotlib decide tick locations for readability\n",
    "        pass\n",
    "\n",
    "    # Add legend\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    # Custom sort order for legend: Actual, Median, then PIs (already ordered by plotting)\n",
    "    # If specific order is needed and not achieved by plotting order:\n",
    "    # order_preference = [\"Actual\", median_label_text] + quantile_labels\n",
    "    # sorted_legend = sorted(zip(handles, labels), key=lambda x: order_preference.index(x[1]) if x[1] in order_preference else float('inf'))\n",
    "    # handles = [h for h, l in sorted_legend]\n",
    "    # labels = [l for h, l in sorted_legend]\n",
    "    ax.legend(handles, labels, loc='upper left', bbox_to_anchor=(1.02, 1))\n",
    "\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1]) # Adjust layout to make space for the legend outside\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74104520",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=test_pred_x_raw.output.prediction.reshape(-1, 7)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "078df0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the reshape did not break the order of data\n",
    "diff=torch.empty(size=(14,1))\n",
    "for i in range(13):\n",
    "    diff[i]=sum(sum(pred[0+i*2:2+i*2,]-test_pred_x_raw.output.prediction[i,...])).cpu()\n",
    "sum(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e007a9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_idx=test_pred_x_raw.x[\"decoder_time_idx\"].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5345126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=torch.cat((time_idx, pred), dim=1) #add the time index of the predictions as col=0\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5af832ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to get the avg of the duplicate rows\n",
    "def average_duplicate_rows(tensor, column_index):\n",
    "    \"\"\"\n",
    "    Calculates the average of other columns for duplicate rows based on values in a specified column.\n",
    "\n",
    "    Args:\n",
    "        tensor: A 2D PyTorch tensor.\n",
    "        column_index: The index of the column used for identifying duplicate rows.\n",
    "\n",
    "    Returns:\n",
    "        A new tensor with averaged rows.\n",
    "    \"\"\"\n",
    "\n",
    "    if tensor.ndim != 2:\n",
    "      raise ValueError(\"Input tensor must be 2D.\")\n",
    "    \n",
    "    if column_index >= tensor.shape[1]:\n",
    "        raise IndexError(\"column_index out of range\")\n",
    "    \n",
    "    # Convert to NumPy array for easier manipulation\n",
    "    tensor_np = tensor.numpy()\n",
    "\n",
    "    # Get unique values in the specified column and their indices\n",
    "    unique_values, inverse_indices = torch.unique(tensor[:, column_index], return_inverse=True)\n",
    "    unique_values = unique_values.numpy()\n",
    "    inverse_indices = inverse_indices.numpy()\n",
    "\n",
    "    # Create a dictionary to store rows for each unique value\n",
    "    grouped_rows = {}\n",
    "    for i, val in enumerate(inverse_indices):\n",
    "        if val not in grouped_rows:\n",
    "          grouped_rows[val] = []\n",
    "        grouped_rows[val].append(tensor_np[i])\n",
    "\n",
    "    # Calculate the average of other columns for each group\n",
    "    averaged_rows = []\n",
    "    for _, rows in grouped_rows.items():\n",
    "        rows = torch.tensor(rows) #convert list of rows to tensor\n",
    "        averaged_row = rows.mean(dim=0)\n",
    "        averaged_rows.append(averaged_row)\n",
    "    \n",
    "    averaged_rows = torch.stack(averaged_rows)\n",
    "\n",
    "    return averaged_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "15f7c1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_avg = average_duplicate_rows(pred.cpu(), 0)\n",
    "pred_avg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86f6579",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_plot=pred_avg[:, 1:] #remove the time index column\n",
    "pred_plot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "da9275cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4b5a4c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define Quantile Labels based on SPECIFIC_QUANTILE_LEVELS ---\n",
    "# These labels will be passed to the plotting function.\n",
    "SPECIFIC_QUANTILE_LEVELS= [0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98] # The quantile levels used in the model\n",
    "\n",
    "# The function can also generate them if quantile_levels are passed.\n",
    "# Order: Outermost, Middle, Innermost\n",
    "pi_outer_label = f\"{(SPECIFIC_QUANTILE_LEVELS[6] - SPECIFIC_QUANTILE_LEVELS[0])*100:.0f}% PI ({SPECIFIC_QUANTILE_LEVELS[0]:.2f}-{SPECIFIC_QUANTILE_LEVELS[6]:.2f})\"\n",
    "pi_mid_label = f\"{(SPECIFIC_QUANTILE_LEVELS[5] - SPECIFIC_QUANTILE_LEVELS[1])*100:.0f}% PI ({SPECIFIC_QUANTILE_LEVELS[1]:.2f}-{SPECIFIC_QUANTILE_LEVELS[5]:.2f})\"\n",
    "pi_inner_label = f\"{(SPECIFIC_QUANTILE_LEVELS[4] - SPECIFIC_QUANTILE_LEVELS[2])*100:.0f}% PI ({SPECIFIC_QUANTILE_LEVELS[2]:.2f}-{SPECIFIC_QUANTILE_LEVELS[4]:.2f})\"\n",
    "    \n",
    "# The order in custom_labels MUST match the order of plotting fill_between\n",
    "# which is from outermost to innermost (j=0 to num_features//2 - 1)\n",
    "custom_interval_labels = [pi_outer_label, pi_mid_label, pi_inner_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c8859b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot the Tensors ---\n",
    "print(f\"Tensor1 (predictions) shape: {pred_plot.shape}\")\n",
    "print(f\"Tensor2 (actuals) shape: {test_plot.shape}\")\n",
    "print(f\"Quantile levels being plotted: {SPECIFIC_QUANTILE_LEVELS}\")\n",
    "\n",
    "plot_single_timeseries_quantile_predictions(\n",
    "    pred_plot,\n",
    "    test_plot,\n",
    "    quantile_levels=SPECIFIC_QUANTILE_LEVELS,\n",
    "    quantile_labels=custom_interval_labels, # Pass the correctly ordered labels\n",
    "    title=\"Sample Time Series Prediction with Quantiles\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
